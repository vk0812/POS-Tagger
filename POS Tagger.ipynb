{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1131c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functions import get_word_tag,preprocess\n",
    "from collections import defaultdict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39e1966c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In\\tIN\\n', 'an\\tDT\\n', 'Oct.\\tNNP\\n', '19\\tCD\\n', 'review\\tNN\\n']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('train.pos','r') as f:\n",
    "    train = f.readlines()\n",
    "    \n",
    "train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "938c6530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '#', '$', '%', '&', \"'\", \"''\", \"'40s\", \"'60s\", \"'70s\", \"'80s\", \"'86\", \"'90s\", \"'N\", \"'S\", \"'d\", \"'em\", \"'ll\", \"'m\", \"'n'\", \"'re\", \"'s\", \"'til\", \"'ve\", '(', ')', ',', '-', '--', '--n--', '--unk--', '--unk_adj--', '--unk_adv--', '--unk_digit--', '--unk_noun--', '--unk_punct--', '--unk_upper--', '--unk_verb--', '.', '...', '0.01', '0.0108', '0.02', '0.03', '0.05', '0.1', '0.10', '0.12', '0.13', '0.15']\n",
      "\n",
      " ['yards', 'yardstick', 'year', 'year-ago', 'year-before', 'year-earlier', 'year-end', 'year-on-year', 'year-round', 'year-to-date', 'year-to-year', 'yearlong', 'yearly', 'years', 'yeast', 'yelled', 'yelling', 'yellow', 'yen', 'yes', 'yesterday', 'yet', 'yield', 'yielded', 'yielding', 'yields', 'you', 'young', 'younger', 'youngest', 'youngsters', 'your', 'yourself', 'youth', 'youthful', 'yuppie', 'yuppies', 'zero', 'zero-coupon', 'zeroing', 'zeros', 'zinc', 'zip', 'zombie', 'zone', 'zones', 'zoning', '{', '}', '']\n"
     ]
    }
   ],
   "source": [
    "with open('vocab.txt','r') as f:\n",
    "    vocab = f.read().split('\\n')\n",
    "\n",
    "print(vocab[0:50]) # first 50 words\n",
    "print('\\n',vocab[-50:]) # last 50  words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a03ea899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":0\n",
      "!:1\n",
      "#:2\n",
      "$:3\n",
      "%:4\n",
      "&:5\n",
      "':6\n",
      "'':7\n",
      "'40s:8\n",
      "'60s:9\n",
      "'70s:10\n"
     ]
    }
   ],
   "source": [
    "vocab_dict = {}\n",
    "for i,word in enumerate(sorted(vocab)):\n",
    "    vocab_dict[word] = i\n",
    "    \n",
    "c=0\n",
    "for a,b in vocab_dict.items():\n",
    "    print(f\"{a}:{b}\")\n",
    "    c=c+1\n",
    "    if(c>10):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "def95c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The\\tDT\\n', 'economy\\tNN\\n', \"'s\\tPOS\\n\", 'temperature\\tNN\\n', 'will\\tMD\\n', 'be\\tVB\\n', 'taken\\tVBN\\n', 'from\\tIN\\n', 'several\\tJJ\\n', 'vantage\\tNN\\n']\n"
     ]
    }
   ],
   "source": [
    "with open('test.pos','r') as f:\n",
    "    y = f.readlines()\n",
    "\n",
    "print(y[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca01c848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34199\n",
      "['The', 'economy', \"'s\", 'temperature', 'will', 'be', 'taken', 'from', 'several', '--unk--']\n"
     ]
    }
   ],
   "source": [
    "_,prep = preprocess(vocab,'test.words')\n",
    "print(len(prep))\n",
    "print(prep[0:10])\n",
    "# 10th word is 'vantage' which is not in vocab therefore --unk--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4584f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrices(training,vocab):\n",
    "    emission_counts = defaultdict(int)\n",
    "    transistion_counts = defaultdict(int)\n",
    "    tag_counts = defaultdict(int)\n",
    "    prev_tag = '--s--'\n",
    "    i=0\n",
    "    for word_tag in training:\n",
    "        \n",
    "        i+=1\n",
    "        if(i%50000==0):\n",
    "            print(f\"Iteration: {i}\")\n",
    "        \n",
    "        word,tag = get_word_tag(word_tag,vocab)\n",
    "        \n",
    "        emission_counts[(tag,word)]+=1\n",
    "        transistion_counts[(prev_tag,tag)]+=1\n",
    "        tag_counts[tag]+=1\n",
    "        \n",
    "        prev_tag = tag\n",
    "    \n",
    "    return emission_counts,transistion_counts,tag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "052b97ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 50000\n",
      "Iteration: 100000\n",
      "Iteration: 150000\n",
      "Iteration: 200000\n",
      "Iteration: 250000\n",
      "Iteration: 300000\n",
      "Iteration: 350000\n",
      "Iteration: 400000\n",
      "Iteration: 450000\n",
      "Iteration: 500000\n",
      "Iteration: 550000\n",
      "Iteration: 600000\n",
      "Iteration: 650000\n",
      "Iteration: 700000\n",
      "Iteration: 750000\n",
      "Iteration: 800000\n",
      "Iteration: 850000\n",
      "Iteration: 900000\n",
      "Iteration: 950000\n"
     ]
    }
   ],
   "source": [
    "emission_counts,transistion_counts,tag_counts = matrices(train,vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86a4b00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "['#', '$', \"''\", '(', ')', ',', '--s--', '.', ':', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB', '``']\n"
     ]
    }
   ],
   "source": [
    "hidden_states = sorted(tag_counts.keys())\n",
    "print(len(hidden_states))\n",
    "print(hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99adb9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(prep,vocab,emission_counts,states,y):\n",
    "    correct = 0\n",
    "    total = len(prep)\n",
    "    \n",
    "    for word,y_tup in zip(prep,y):\n",
    "        y_tup_l = y_tup.split()\n",
    "        if len(y_tup_l) == 2:\n",
    "            true_label = y_tup_l[1]\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        if word in vocab:\n",
    "            count = 0\n",
    "            pos_pred = '' \n",
    "            for pos in states:\n",
    "                aa = emission_counts[(pos,word)]\n",
    "                if(aa>count):\n",
    "                    count = aa\n",
    "                    pos_pred = pos\n",
    "            \n",
    "            if(pos_pred == true_label):\n",
    "                correct = correct + 1\n",
    "    accuracy = correct/total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcfe77ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.88563993099213"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(prep,vocab,emission_counts,hidden_states,y)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e4faf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 88.88% Accuracy\n",
    "# Increasing the Accuracy using the Hidden Markov Models and the Viterbi Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac6b6ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transistion_matrix(epsilon,transistion_counts,tag_counts):\n",
    "    all_tags = sorted(tag_counts.keys())\n",
    "    N = len(all_tags)\n",
    "    \n",
    "    t_matrix = np.zeros((N,N))\n",
    "    \n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            key = (all_tags[i],all_tags[j])\n",
    "            count = tag_counts[(all_tags[i])]\n",
    "            t_matrix[i][j] = (transistion_counts[(key)]+epsilon)/(count+(N*epsilon))\n",
    "    \n",
    "    return t_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18545403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emission_matrix(epsilon,tag_counts,emission_counts,vocab):\n",
    "    all_tags = sorted(tag_counts.keys())\n",
    "    N = len(all_tags)\n",
    "    m = len(vocab)\n",
    "    e_matrix = np.zeros((N,m))\n",
    "    for i in range(N):\n",
    "        for j in range(m):\n",
    "            count = tag_counts[all_tags[i]]\n",
    "            key = (all_tags[i],vocab[j])\n",
    "            e_matrix[i][j] = (emission_counts[key]+epsilon)/(count+(m*epsilon))\n",
    "    return e_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0432913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_matrix = transistion_matrix(0.001,transistion_counts,tag_counts)\n",
    "e_matrix = emission_matrix(0.001,tag_counts,emission_counts,list(vocab_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "427dd852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(states,A,B,tag_counts,vocab,prep):\n",
    "    N = len(tag_counts)\n",
    "    m = len(prep)\n",
    "    \n",
    "    best_probs = np.zeros((N,m))\n",
    "    best_paths = np.zeros((N,m),dtype=int)\n",
    "    s_idx = states.index('--s--')\n",
    "    \n",
    "    for i in range(N):\n",
    "        if A[s_idx][i]==0:\n",
    "            best_probs[i][0] = float('-inf')\n",
    "        else:\n",
    "            best_probs[i][0] = math.log(A[s_idx][i]) + math.log(B[i][vocab[prep[0]]])\n",
    "            # vocab[corpus[0]] gives you the index of the first test word in the matrix B(e_matrix) \n",
    "    return best_probs,best_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a42787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_probs,best_paths = initialize(hidden_states,t_matrix,e_matrix,tag_counts,vocab_dict,prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1832f9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_forward(A, B, prep, best_probs, best_paths, vocab):\n",
    "    N = best_probs.shape[0]\n",
    "\n",
    "    for i in range(1, len(prep)): # first array for words in the corpus\n",
    "        if i % 5000 == 0:\n",
    "            print(\"Words processed: {:>8}\".format(i))\n",
    "\n",
    "        for j in range(N): # second array for present word pos tag\n",
    "            best_prob_i =  float(\"-inf\")\n",
    "            best_path_i = None\n",
    "\n",
    "            for k in range(N): # third array for previous word pos tag\n",
    "                prob = best_probs[k,i-1]+math.log(A[k,j]) +math.log(B[j,vocab[prep[i]]])\n",
    "                if prob > best_prob_i: # calculating max prob happens from which pos tag\n",
    "                    best_prob_i = prob \n",
    "                    best_path_i = k \n",
    "\n",
    "            best_probs[j,i] = best_prob_i # storing max prob in best_prob\n",
    "            best_paths[j,i] = best_path_i # storing index of prev pos tag in best_path\n",
    "\n",
    "    return best_probs, best_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2cc30a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words processed:     5000\n",
      "Words processed:    10000\n",
      "Words processed:    15000\n",
      "Words processed:    20000\n",
      "Words processed:    25000\n",
      "Words processed:    30000\n"
     ]
    }
   ],
   "source": [
    "best_probs, best_paths = viterbi_forward(t_matrix, e_matrix, prep, best_probs, best_paths, vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06f7b1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_backward(best_probs, best_paths, prep, states):\n",
    "    m = best_paths.shape[1] \n",
    "    z = [None] * m\n",
    "    N = best_probs.shape[0]\n",
    "    best_prob_for_last_word = float('-inf')\n",
    "    pred = [None] * m\n",
    "    \n",
    "    for k in range(N): \n",
    "        if best_probs[k,-1]>best_prob_for_last_word: \n",
    "            best_prob_for_last_word = best_probs[k,-1]\n",
    "            z[m-1]=k\n",
    "            \n",
    "    pred[m-1] = states[z[m-1]]\n",
    "    \n",
    "    for i in range(len(prep)-1, -1, -1): # to go from len(prep)-1 to 0 with i=i-1 at each iteration\n",
    "        pos_tag_for_word_i = best_paths[np.argmax(best_probs[:,i]),i]\n",
    "        z[i-1] = best_paths[pos_tag_for_word_i,i]\n",
    "        pred[i-1] = states[pos_tag_for_word_i]\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7dd52679",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = viterbi_backward(best_probs, best_paths, prep, hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c40041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(pred, y):\n",
    "    num_correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for prediction, y in zip(pred, y):\n",
    "        word_tag_tuple = y.split()\n",
    "        if len(word_tag_tuple)!=2:\n",
    "            continue \n",
    "        word, tag = word_tag_tuple\n",
    "        if prediction == tag: \n",
    "            num_correct += 1\n",
    "        total += 1\n",
    "    \n",
    "    return (num_correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a021b1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 95.27592609502938\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy is {compute_accuracy(pred, y)*100}\")\n",
    "# Thus a 7% rise in accuracy using  the Hidden Markov Model and Viterbi Algorithm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
